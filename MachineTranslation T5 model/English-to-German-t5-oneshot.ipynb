{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference Code using t_5_small_model English to German"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input English sentence: Obama receives Netanyahu\n",
      "Translated German sentence: Obama erhält Netanjahu\n",
      "Input English sentence: The relationship between Obama and Netanyahu is not exactly friendly.\n",
      "Translated German sentence: Die Beziehung zwischen Obama und Netanjahu ist nicht gerade freundlich.\n",
      "Input English sentence: The two wanted to talk about the implementation of the international agreement and about Teheran's destabilising activities in the Middle East.\n",
      "Translated German sentence: Die beiden wollten über die Umsetzung des internationalen Abkommens und über Teherans destabilisierende Aktivitäten im Nahen Osten sprechen.\n",
      "Input English sentence: The meeting was also planned to cover the conflict with the Palestinians and the disputed two state solution.\n",
      "Translated German sentence: Das Treffen sollte auch den Konflikt mit den Palästinensern und die umstrittene zweistaatliche Lösung abdecken.\n",
      "Input English sentence: Relations between Obama and Netanyahu have been strained for years.\n",
      "Translated German sentence: Die Beziehungen zwischen Obama und Netanjahu sind seit Jahren angespannt.\n",
      "Translation completed. Translated CSV saved to ta_data_output_ge_en.csv.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
    "\n",
    "# Load pre-trained T5 model and tokenizer\n",
    "model_name = \"t5-small\"\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_name)\n",
    "tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Function to translate a single English sentence to German\n",
    "def translate_sentence(english_sentence):\n",
    "    try:\n",
    "        print(\"Input English sentence:\", english_sentence)\n",
    "        # Tokenize input text\n",
    "        inputs = tokenizer.encode(\"translate English to German: \" + english_sentence, return_tensors=\"pt\", max_length=512, truncation=True)\n",
    "        \n",
    "        # Generate translation\n",
    "        with torch.no_grad():\n",
    "            outputs = model.generate(inputs, max_length=100, num_beams=4, early_stopping=True)\n",
    "        \n",
    "        # Decode the generated translation\n",
    "        translated_sentence = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "        print(\"Translated German sentence:\", translated_sentence)\n",
    "        return translated_sentence\n",
    "    except Exception as e:\n",
    "        print(\"Error during translation:\", e)\n",
    "        return \"\"\n",
    "\n",
    "# Function to translate English sentences in a CSV file and output translated CSV\n",
    "def translate_csv(input_csv_path, output_csv_path):\n",
    "    try:\n",
    "        # Read input CSV\n",
    "        df = pd.read_csv(input_csv_path)\n",
    "        \n",
    "        # Translate English sentences\n",
    "        df['de'] = df['en'].apply(translate_sentence)  # Update column names\n",
    "        \n",
    "        # Save translated CSV\n",
    "        df.to_csv(output_csv_path, index=False)\n",
    "        \n",
    "        print(f\"Translation completed. Translated CSV saved to {output_csv_path}.\")\n",
    "    except Exception as e:\n",
    "        print(\"Error during translation:\", e)\n",
    "\n",
    "# Run translation pipeline for CSV input and output\n",
    "input_csv_path = \"/test_data.csv\"\n",
    "output_csv_path = \"output.csv\"  # Update output file name\n",
    "translate_csv(input_csv_path, output_csv_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From English to German"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/seraj/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
    "from datasets import load_dataset\n",
    "from bert_score import score\n",
    "from sacrebleu import corpus_bleu\n",
    "import os\n",
    "import nltk\n",
    "from nltk.translate import meteor_score\n",
    "\n",
    "# Download necessary NLTK data\n",
    "nltk.download(\"wordnet\")\n",
    "\n",
    "# Set CUDA_VISIBLE_DEVICES environment variable\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "# Load pre-trained T5 model and tokenizer\n",
    "model_name = \"t5-small\"\n",
    "tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_name)\n",
    "\n",
    "# Set device to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Load the training dataset (50,000 examples)\n",
    "train_data = load_dataset(\"wmt16\", \"de-en\", split=\"train[:50000]\")\n",
    "\n",
    "# Load the validation dataset\n",
    "val_data = load_dataset(\"wmt16\", \"de-en\", split=\"validation\")\n",
    "\n",
    "# Load the test dataset\n",
    "test_data = load_dataset(\"wmt16\", \"de-en\", split=\"test\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>de</th>\n",
       "      <th>en</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Die Premierminister Indiens und Japans trafen ...</td>\n",
       "      <td>India and Japan prime ministers meet in Tokyo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Indiens neuer Premierminister Narendra Modi tr...</td>\n",
       "      <td>India's new prime minister, Narendra Modi, is ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Herr Modi befindet sich auf einer fünftägigen ...</td>\n",
       "      <td>Mr Modi is on a five-day trip to Japan to stre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pläne für eine stärkere kerntechnische Zusamme...</td>\n",
       "      <td>High on the agenda are plans for greater nucle...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Berichten zufolge hofft Indien darüber hinaus ...</td>\n",
       "      <td>India is also reportedly hoping for a deal on ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2164</th>\n",
       "      <td>Die Wanderer zuerst um 9.30 Uhr.</td>\n",
       "      <td>The walkers started at 9.30 am.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2165</th>\n",
       "      <td>Es folgten die ersten Radfahrer und Läufer um ...</td>\n",
       "      <td>Then it was the turn of the cyclists and runne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2166</th>\n",
       "      <td>Fünf Minuten später legten die ersten Mountain...</td>\n",
       "      <td>Five minutes later the first Mountain-bikers s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2167</th>\n",
       "      <td>Bent Hansen, Vorsitzender des Vereins \"Radeln ...</td>\n",
       "      <td>Bent Hansen, Chairman of the Association 'Cycl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2168</th>\n",
       "      <td>Für nächstes Jahr hoffe er, dass es gelingt, d...</td>\n",
       "      <td>Next year, he hopes to have safety barriers on...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2169 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     de  \\\n",
       "0     Die Premierminister Indiens und Japans trafen ...   \n",
       "1     Indiens neuer Premierminister Narendra Modi tr...   \n",
       "2     Herr Modi befindet sich auf einer fünftägigen ...   \n",
       "3     Pläne für eine stärkere kerntechnische Zusamme...   \n",
       "4     Berichten zufolge hofft Indien darüber hinaus ...   \n",
       "...                                                 ...   \n",
       "2164                   Die Wanderer zuerst um 9.30 Uhr.   \n",
       "2165  Es folgten die ersten Radfahrer und Läufer um ...   \n",
       "2166  Fünf Minuten später legten die ersten Mountain...   \n",
       "2167  Bent Hansen, Vorsitzender des Vereins \"Radeln ...   \n",
       "2168  Für nächstes Jahr hoffe er, dass es gelingt, d...   \n",
       "\n",
       "                                                     en  \n",
       "0         India and Japan prime ministers meet in Tokyo  \n",
       "1     India's new prime minister, Narendra Modi, is ...  \n",
       "2     Mr Modi is on a five-day trip to Japan to stre...  \n",
       "3     High on the agenda are plans for greater nucle...  \n",
       "4     India is also reportedly hoping for a deal on ...  \n",
       "...                                                 ...  \n",
       "2164                    The walkers started at 9.30 am.  \n",
       "2165  Then it was the turn of the cyclists and runne...  \n",
       "2166  Five minutes later the first Mountain-bikers s...  \n",
       "2167  Bent Hansen, Chairman of the Association 'Cycl...  \n",
       "2168  Next year, he hopes to have safety barriers on...  \n",
       "\n",
       "[2169 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Extract German and English translations\n",
    "translations_val_df = [{\"de\": item[\"translation\"][\"de\"], \"en\": item[\"translation\"][\"en\"]} for item in val_data]\n",
    "\n",
    "# Convert translations to Pandas DataFrame\n",
    "val_df = pd.DataFrame(translations_val_df)\n",
    "\n",
    "# Display the DataFrame\n",
    "val_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>de</th>\n",
       "      <th>en</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Obama empfängt Netanyahu</td>\n",
       "      <td>Obama receives Netanyahu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Das Verhältnis zwischen Obama und Netanyahu is...</td>\n",
       "      <td>The relationship between Obama and Netanyahu i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Die beiden wollten über die Umsetzung der inte...</td>\n",
       "      <td>The two wanted to talk about the implementatio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bei der Begegnung soll es aber auch um den Kon...</td>\n",
       "      <td>The meeting was also planned to cover the conf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Das Verhältnis zwischen Obama und Netanyahu is...</td>\n",
       "      <td>Relations between Obama and Netanyahu have bee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2994</th>\n",
       "      <td>Quecksilber gelangt vor allem durch die Kohlev...</td>\n",
       "      <td>Mercury is released into the environment prima...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2995</th>\n",
       "      <td>Die deutschen Kohlekraftwerke stoßen laut eine...</td>\n",
       "      <td>German coal plants, according to written infor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>Die Konzentration von Quecksilber in Fischen e...</td>\n",
       "      <td>The concentration of mercury in fish, for exam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>Im vergangenen Jahr zählten europaweite Warnun...</td>\n",
       "      <td>In the past year, Europe-wide alerts on mercur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>Foodwatch ruft Verbraucher zum Protest gegen d...</td>\n",
       "      <td>Foodwatch is calling for consumers to protest ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2999 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     de  \\\n",
       "0                              Obama empfängt Netanyahu   \n",
       "1     Das Verhältnis zwischen Obama und Netanyahu is...   \n",
       "2     Die beiden wollten über die Umsetzung der inte...   \n",
       "3     Bei der Begegnung soll es aber auch um den Kon...   \n",
       "4     Das Verhältnis zwischen Obama und Netanyahu is...   \n",
       "...                                                 ...   \n",
       "2994  Quecksilber gelangt vor allem durch die Kohlev...   \n",
       "2995  Die deutschen Kohlekraftwerke stoßen laut eine...   \n",
       "2996  Die Konzentration von Quecksilber in Fischen e...   \n",
       "2997  Im vergangenen Jahr zählten europaweite Warnun...   \n",
       "2998  Foodwatch ruft Verbraucher zum Protest gegen d...   \n",
       "\n",
       "                                                     en  \n",
       "0                              Obama receives Netanyahu  \n",
       "1     The relationship between Obama and Netanyahu i...  \n",
       "2     The two wanted to talk about the implementatio...  \n",
       "3     The meeting was also planned to cover the conf...  \n",
       "4     Relations between Obama and Netanyahu have bee...  \n",
       "...                                                 ...  \n",
       "2994  Mercury is released into the environment prima...  \n",
       "2995  German coal plants, according to written infor...  \n",
       "2996  The concentration of mercury in fish, for exam...  \n",
       "2997  In the past year, Europe-wide alerts on mercur...  \n",
       "2998  Foodwatch is calling for consumers to protest ...  \n",
       "\n",
       "[2999 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract German and English translations\n",
    "translations_test_data = [{\"de\": item[\"translation\"][\"de\"], \"en\": item[\"translation\"][\"en\"]} for item in test_data]\n",
    "\n",
    "# Convert translations to Pandas DataFrame\n",
    "test_df = pd.DataFrame(translations_test_data)\n",
    "\n",
    "# Display the DataFrame\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/seraj/miniconda3/envs/kill/lib/python3.10/site-packages/datasets/load.py:756: FutureWarning: The repository for meteor contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/meteor/meteor.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "[nltk_data] Downloading package wordnet to /home/seraj/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/seraj/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/seraj/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation METEOR: 0.5515488896080301\n",
      "Validation BERTScore: 0.6489973664283752\n",
      "Validation BLEU-1: 0.8645239244176106\n",
      "Validation BLEU-2: 0.785705432461213\n",
      "Validation BLEU-3: 0.7205451711521605\n",
      "Validation BLEU-4: 0.6694257941058802\n",
      "Test METEOR: 0.5902469429945494\n",
      "Test BERTScore: 0.6776204705238342\n",
      "Test BLEU-1: 0.871053573206133\n",
      "Test BLEU-2: 0.8009281409830009\n",
      "Test BLEU-3: 0.742822494487264\n",
      "Test BLEU-4: 0.6966520372661966\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
    "from datasets import load_metric\n",
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "import pandas as pd\n",
    "from bert_score import BERTScorer\n",
    "\n",
    "# Load evaluation metrics\n",
    "meteor_score = load_metric(\"meteor\")\n",
    "scorer = BERTScorer(lang=\"de\", rescale_with_baseline=True)\n",
    "\n",
    "# Function to translate sentences from English to German\n",
    "def translate_sentences(sentences):\n",
    "    translations = []\n",
    "    for sentence in sentences:\n",
    "        # Prepend the prefix to the input sentence for English to German translation\n",
    "        input_text = \"translate English to German: \" + sentence[\"en\"]\n",
    "        # Tokenize input text\n",
    "        input_ids = tokenizer.encode(input_text, return_tensors=\"pt\", max_length=512, truncation=True).to(device)\n",
    "        # Generate translation\n",
    "        with torch.no_grad():\n",
    "            outputs = model.generate(input_ids=input_ids, max_length=100, num_beams=4, early_stopping=True)\n",
    "        # Decode the generated translation\n",
    "        translation = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "        translations.append(translation)\n",
    "    return translations\n",
    "\n",
    "# Function to compute METEOR score for German to English translation\n",
    "def compute_meteor(references, predictions):\n",
    "    return meteor_score.compute(predictions=predictions, references=references)[\"meteor\"]\n",
    "\n",
    "# Function to compute BERTScore for German to English translation\n",
    "def compute_bertscore(references, predictions):\n",
    "    P, R, F1 = scorer.score(references, predictions)\n",
    "    return F1.mean().item()\n",
    "\n",
    "# Function to compute BLEU score for specified n-gram order\n",
    "def compute_bleu_ngram(references, predictions, ngram_order):\n",
    "    return corpus_bleu([[ref] for ref in references], predictions, weights=(1/ngram_order,)*ngram_order)\n",
    "\n",
    "# Translate validation and test sets\n",
    "val_translations = translate_sentences(val_df.to_dict(\"records\"))\n",
    "test_translations = translate_sentences(test_df.to_dict(\"records\"))\n",
    "\n",
    "# Extract reference translations from validation and test sets\n",
    "val_references = val_df[\"de\"].tolist()\n",
    "test_references = test_df[\"de\"].tolist()\n",
    "\n",
    "# Compute evaluation metrics\n",
    "val_meteor = compute_meteor(val_references, val_translations)\n",
    "val_bertscore = compute_bertscore(val_references, val_translations)\n",
    "test_meteor = compute_meteor(test_references, test_translations)\n",
    "test_bertscore = compute_bertscore(test_references, test_translations)\n",
    "\n",
    "\n",
    "# Compute BLEU scores for validation and test data\n",
    "val_bleu1 = compute_bleu_ngram(val_translations, val_references, 1)\n",
    "val_bleu2 = compute_bleu_ngram(val_translations, val_references, 2)\n",
    "val_bleu3 = compute_bleu_ngram(val_translations, val_references, 3)\n",
    "val_bleu4 = compute_bleu_ngram(val_translations, val_references, 4)\n",
    "\n",
    "test_bleu1 = compute_bleu_ngram(test_translations, test_references, 1)\n",
    "test_bleu2 = compute_bleu_ngram(test_translations, test_references, 2)\n",
    "test_bleu3 = compute_bleu_ngram(test_translations, test_references, 3)\n",
    "test_bleu4 = compute_bleu_ngram(test_translations, test_references, 4)\n",
    "\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(\"Validation METEOR:\", val_meteor)\n",
    "print(\"Validation BERTScore:\", val_bertscore)\n",
    "print(\"Validation BLEU-1:\", val_bleu1)\n",
    "print(\"Validation BLEU-2:\", val_bleu2)\n",
    "print(\"Validation BLEU-3:\", val_bleu3)\n",
    "print(\"Validation BLEU-4:\", val_bleu4)\n",
    "\n",
    "print(\"Test METEOR:\", test_meteor)\n",
    "print(\"Test BERTScore:\", test_bertscore)\n",
    "print(\"Test BLEU-1:\", test_bleu1)\n",
    "print(\"Test BLEU-2:\", test_bleu2)\n",
    "print(\"Test BLEU-3:\", test_bleu3)\n",
    "print(\"Test BLEU-4:\", test_bleu4)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
